# WebMD-Informed Responses: Deploying and Fine-Tuning the Llama 2 7b Model on Azure ML

In this project, we operationalized a Generative AI model, specifically the Large Language Model Llama 2 with a 7-billion parameter configuration, sourced from the Hugging Face platform. Our primary objective was to provide a comprehensive setup and tuning mechanism on the MLOps platform, Azure ML.

Key Technical Highlights:

1. **Model Selection and Source:** We selected the Llama 2 model, a 7-billion parameter variant, from the Hugging Face repository. This model represents one of the forefronts in Generative AI capabilities.

2. **Operationalizing on Azure ML:** The model was deployed on Azure Machine Learning, where it underwent a fine-tuning process to further adapt it for our specific requirements and use-cases.

3. **Model Interaction Mechanism:** One of the unique facets of our project was showcasing how one could interact with this Generative AI model. We employed a prompting mechanism, wherein the model was fed prompts, and it generated associated responses.

4. **API Integration:** Post deployment and fine-tuning, we established an API endpoint for the Llama 2 model. This allowed us to programmatically send questions and prompts to the model and subsequently retrieve the model's generated outputs.

5. **Data Utilized for Fine-Tuning:** In order to achieve a specialized response system, we used data scraped from WebMD. This dataset was pivotal in ensuring the responses generated by the Llama 2 model were in alignment with our project's goals.

By employing Azure ML's capabilities in tandem with Llama 2's generative power, we've showcased an end-to-end system, from deployment to interaction, of a Generative AI model.
